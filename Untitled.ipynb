{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c5b0f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T16:27:00.113568Z",
     "start_time": "2023-03-02T16:27:00.112047Z"
    }
   },
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f42bbe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T16:27:12.412606Z",
     "start_time": "2023-03-02T16:27:12.410133Z"
    }
   },
   "outputs": [],
   "source": [
    "b = [*a, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae4f8b18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T16:27:14.784093Z",
     "start_time": "2023-03-02T16:27:14.779160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d1eeac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T14:48:04.113554Z",
     "start_time": "2023-03-03T14:48:04.111264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3382c2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-03T15:00:40.829570Z",
     "start_time": "2023-03-03T15:00:40.827444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9970"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7470+830+1670"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9c4dc81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T11:44:24.530718Z",
     "start_time": "2023-03-05T11:44:23.722062Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8841c5e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T11:50:12.824465Z",
     "start_time": "2023-03-05T11:50:12.669260Z"
    }
   },
   "outputs": [],
   "source": [
    "w = torch.load('bin/teachers/best_vit_base16_photo.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd131fa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T11:49:33.811754Z",
     "start_time": "2023-03-05T11:49:33.809658Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['module.cls_token', 'module.pos_embed', 'module.patch_embed.proj.weight', 'module.patch_embed.proj.bias', 'module.blocks.0.norm1.weight', 'module.blocks.0.norm1.bias', 'module.blocks.0.attn.qkv.weight', 'module.blocks.0.attn.qkv.bias', 'module.blocks.0.attn.proj.weight', 'module.blocks.0.attn.proj.bias', 'module.blocks.0.norm2.weight', 'module.blocks.0.norm2.bias', 'module.blocks.0.mlp.fc1.weight', 'module.blocks.0.mlp.fc1.bias', 'module.blocks.0.mlp.fc2.weight', 'module.blocks.0.mlp.fc2.bias', 'module.blocks.1.norm1.weight', 'module.blocks.1.norm1.bias', 'module.blocks.1.attn.qkv.weight', 'module.blocks.1.attn.qkv.bias', 'module.blocks.1.attn.proj.weight', 'module.blocks.1.attn.proj.bias', 'module.blocks.1.norm2.weight', 'module.blocks.1.norm2.bias', 'module.blocks.1.mlp.fc1.weight', 'module.blocks.1.mlp.fc1.bias', 'module.blocks.1.mlp.fc2.weight', 'module.blocks.1.mlp.fc2.bias', 'module.blocks.2.norm1.weight', 'module.blocks.2.norm1.bias', 'module.blocks.2.attn.qkv.weight', 'module.blocks.2.attn.qkv.bias', 'module.blocks.2.attn.proj.weight', 'module.blocks.2.attn.proj.bias', 'module.blocks.2.norm2.weight', 'module.blocks.2.norm2.bias', 'module.blocks.2.mlp.fc1.weight', 'module.blocks.2.mlp.fc1.bias', 'module.blocks.2.mlp.fc2.weight', 'module.blocks.2.mlp.fc2.bias', 'module.blocks.3.norm1.weight', 'module.blocks.3.norm1.bias', 'module.blocks.3.attn.qkv.weight', 'module.blocks.3.attn.qkv.bias', 'module.blocks.3.attn.proj.weight', 'module.blocks.3.attn.proj.bias', 'module.blocks.3.norm2.weight', 'module.blocks.3.norm2.bias', 'module.blocks.3.mlp.fc1.weight', 'module.blocks.3.mlp.fc1.bias', 'module.blocks.3.mlp.fc2.weight', 'module.blocks.3.mlp.fc2.bias', 'module.blocks.4.norm1.weight', 'module.blocks.4.norm1.bias', 'module.blocks.4.attn.qkv.weight', 'module.blocks.4.attn.qkv.bias', 'module.blocks.4.attn.proj.weight', 'module.blocks.4.attn.proj.bias', 'module.blocks.4.norm2.weight', 'module.blocks.4.norm2.bias', 'module.blocks.4.mlp.fc1.weight', 'module.blocks.4.mlp.fc1.bias', 'module.blocks.4.mlp.fc2.weight', 'module.blocks.4.mlp.fc2.bias', 'module.blocks.5.norm1.weight', 'module.blocks.5.norm1.bias', 'module.blocks.5.attn.qkv.weight', 'module.blocks.5.attn.qkv.bias', 'module.blocks.5.attn.proj.weight', 'module.blocks.5.attn.proj.bias', 'module.blocks.5.norm2.weight', 'module.blocks.5.norm2.bias', 'module.blocks.5.mlp.fc1.weight', 'module.blocks.5.mlp.fc1.bias', 'module.blocks.5.mlp.fc2.weight', 'module.blocks.5.mlp.fc2.bias', 'module.blocks.6.norm1.weight', 'module.blocks.6.norm1.bias', 'module.blocks.6.attn.qkv.weight', 'module.blocks.6.attn.qkv.bias', 'module.blocks.6.attn.proj.weight', 'module.blocks.6.attn.proj.bias', 'module.blocks.6.norm2.weight', 'module.blocks.6.norm2.bias', 'module.blocks.6.mlp.fc1.weight', 'module.blocks.6.mlp.fc1.bias', 'module.blocks.6.mlp.fc2.weight', 'module.blocks.6.mlp.fc2.bias', 'module.blocks.7.norm1.weight', 'module.blocks.7.norm1.bias', 'module.blocks.7.attn.qkv.weight', 'module.blocks.7.attn.qkv.bias', 'module.blocks.7.attn.proj.weight', 'module.blocks.7.attn.proj.bias', 'module.blocks.7.norm2.weight', 'module.blocks.7.norm2.bias', 'module.blocks.7.mlp.fc1.weight', 'module.blocks.7.mlp.fc1.bias', 'module.blocks.7.mlp.fc2.weight', 'module.blocks.7.mlp.fc2.bias', 'module.blocks.8.norm1.weight', 'module.blocks.8.norm1.bias', 'module.blocks.8.attn.qkv.weight', 'module.blocks.8.attn.qkv.bias', 'module.blocks.8.attn.proj.weight', 'module.blocks.8.attn.proj.bias', 'module.blocks.8.norm2.weight', 'module.blocks.8.norm2.bias', 'module.blocks.8.mlp.fc1.weight', 'module.blocks.8.mlp.fc1.bias', 'module.blocks.8.mlp.fc2.weight', 'module.blocks.8.mlp.fc2.bias', 'module.blocks.9.norm1.weight', 'module.blocks.9.norm1.bias', 'module.blocks.9.attn.qkv.weight', 'module.blocks.9.attn.qkv.bias', 'module.blocks.9.attn.proj.weight', 'module.blocks.9.attn.proj.bias', 'module.blocks.9.norm2.weight', 'module.blocks.9.norm2.bias', 'module.blocks.9.mlp.fc1.weight', 'module.blocks.9.mlp.fc1.bias', 'module.blocks.9.mlp.fc2.weight', 'module.blocks.9.mlp.fc2.bias', 'module.blocks.10.norm1.weight', 'module.blocks.10.norm1.bias', 'module.blocks.10.attn.qkv.weight', 'module.blocks.10.attn.qkv.bias', 'module.blocks.10.attn.proj.weight', 'module.blocks.10.attn.proj.bias', 'module.blocks.10.norm2.weight', 'module.blocks.10.norm2.bias', 'module.blocks.10.mlp.fc1.weight', 'module.blocks.10.mlp.fc1.bias', 'module.blocks.10.mlp.fc2.weight', 'module.blocks.10.mlp.fc2.bias', 'module.blocks.11.norm1.weight', 'module.blocks.11.norm1.bias', 'module.blocks.11.attn.qkv.weight', 'module.blocks.11.attn.qkv.bias', 'module.blocks.11.attn.proj.weight', 'module.blocks.11.attn.proj.bias', 'module.blocks.11.norm2.weight', 'module.blocks.11.norm2.bias', 'module.blocks.11.mlp.fc1.weight', 'module.blocks.11.mlp.fc1.bias', 'module.blocks.11.mlp.fc2.weight', 'module.blocks.11.mlp.fc2.bias', 'module.norm.weight', 'module.norm.bias', 'module.head.weight', 'module.head.bias'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d5b872f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T11:50:23.919241Z",
     "start_time": "2023-03-05T11:50:23.917024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token\n",
      "pos_embed\n",
      "patch_embed.proj.weight\n",
      "patch_embed.proj.bias\n",
      "blocks.0.norm1.weight\n",
      "blocks.0.norm1.bias\n",
      "blocks.0.attn.qkv.weight\n",
      "blocks.0.attn.qkv.bias\n",
      "blocks.0.attn.proj.weight\n",
      "blocks.0.attn.proj.bias\n",
      "blocks.0.norm2.weight\n",
      "blocks.0.norm2.bias\n",
      "blocks.0.mlp.fc1.weight\n",
      "blocks.0.mlp.fc1.bias\n",
      "blocks.0.mlp.fc2.weight\n",
      "blocks.0.mlp.fc2.bias\n",
      "blocks.1.norm1.weight\n",
      "blocks.1.norm1.bias\n",
      "blocks.1.attn.qkv.weight\n",
      "blocks.1.attn.qkv.bias\n",
      "blocks.1.attn.proj.weight\n",
      "blocks.1.attn.proj.bias\n",
      "blocks.1.norm2.weight\n",
      "blocks.1.norm2.bias\n",
      "blocks.1.mlp.fc1.weight\n",
      "blocks.1.mlp.fc1.bias\n",
      "blocks.1.mlp.fc2.weight\n",
      "blocks.1.mlp.fc2.bias\n",
      "blocks.2.norm1.weight\n",
      "blocks.2.norm1.bias\n",
      "blocks.2.attn.qkv.weight\n",
      "blocks.2.attn.qkv.bias\n",
      "blocks.2.attn.proj.weight\n",
      "blocks.2.attn.proj.bias\n",
      "blocks.2.norm2.weight\n",
      "blocks.2.norm2.bias\n",
      "blocks.2.mlp.fc1.weight\n",
      "blocks.2.mlp.fc1.bias\n",
      "blocks.2.mlp.fc2.weight\n",
      "blocks.2.mlp.fc2.bias\n",
      "blocks.3.norm1.weight\n",
      "blocks.3.norm1.bias\n",
      "blocks.3.attn.qkv.weight\n",
      "blocks.3.attn.qkv.bias\n",
      "blocks.3.attn.proj.weight\n",
      "blocks.3.attn.proj.bias\n",
      "blocks.3.norm2.weight\n",
      "blocks.3.norm2.bias\n",
      "blocks.3.mlp.fc1.weight\n",
      "blocks.3.mlp.fc1.bias\n",
      "blocks.3.mlp.fc2.weight\n",
      "blocks.3.mlp.fc2.bias\n",
      "blocks.4.norm1.weight\n",
      "blocks.4.norm1.bias\n",
      "blocks.4.attn.qkv.weight\n",
      "blocks.4.attn.qkv.bias\n",
      "blocks.4.attn.proj.weight\n",
      "blocks.4.attn.proj.bias\n",
      "blocks.4.norm2.weight\n",
      "blocks.4.norm2.bias\n",
      "blocks.4.mlp.fc1.weight\n",
      "blocks.4.mlp.fc1.bias\n",
      "blocks.4.mlp.fc2.weight\n",
      "blocks.4.mlp.fc2.bias\n",
      "blocks.5.norm1.weight\n",
      "blocks.5.norm1.bias\n",
      "blocks.5.attn.qkv.weight\n",
      "blocks.5.attn.qkv.bias\n",
      "blocks.5.attn.proj.weight\n",
      "blocks.5.attn.proj.bias\n",
      "blocks.5.norm2.weight\n",
      "blocks.5.norm2.bias\n",
      "blocks.5.mlp.fc1.weight\n",
      "blocks.5.mlp.fc1.bias\n",
      "blocks.5.mlp.fc2.weight\n",
      "blocks.5.mlp.fc2.bias\n",
      "blocks.6.norm1.weight\n",
      "blocks.6.norm1.bias\n",
      "blocks.6.attn.qkv.weight\n",
      "blocks.6.attn.qkv.bias\n",
      "blocks.6.attn.proj.weight\n",
      "blocks.6.attn.proj.bias\n",
      "blocks.6.norm2.weight\n",
      "blocks.6.norm2.bias\n",
      "blocks.6.mlp.fc1.weight\n",
      "blocks.6.mlp.fc1.bias\n",
      "blocks.6.mlp.fc2.weight\n",
      "blocks.6.mlp.fc2.bias\n",
      "blocks.7.norm1.weight\n",
      "blocks.7.norm1.bias\n",
      "blocks.7.attn.qkv.weight\n",
      "blocks.7.attn.qkv.bias\n",
      "blocks.7.attn.proj.weight\n",
      "blocks.7.attn.proj.bias\n",
      "blocks.7.norm2.weight\n",
      "blocks.7.norm2.bias\n",
      "blocks.7.mlp.fc1.weight\n",
      "blocks.7.mlp.fc1.bias\n",
      "blocks.7.mlp.fc2.weight\n",
      "blocks.7.mlp.fc2.bias\n",
      "blocks.8.norm1.weight\n",
      "blocks.8.norm1.bias\n",
      "blocks.8.attn.qkv.weight\n",
      "blocks.8.attn.qkv.bias\n",
      "blocks.8.attn.proj.weight\n",
      "blocks.8.attn.proj.bias\n",
      "blocks.8.norm2.weight\n",
      "blocks.8.norm2.bias\n",
      "blocks.8.mlp.fc1.weight\n",
      "blocks.8.mlp.fc1.bias\n",
      "blocks.8.mlp.fc2.weight\n",
      "blocks.8.mlp.fc2.bias\n",
      "blocks.9.norm1.weight\n",
      "blocks.9.norm1.bias\n",
      "blocks.9.attn.qkv.weight\n",
      "blocks.9.attn.qkv.bias\n",
      "blocks.9.attn.proj.weight\n",
      "blocks.9.attn.proj.bias\n",
      "blocks.9.norm2.weight\n",
      "blocks.9.norm2.bias\n",
      "blocks.9.mlp.fc1.weight\n",
      "blocks.9.mlp.fc1.bias\n",
      "blocks.9.mlp.fc2.weight\n",
      "blocks.9.mlp.fc2.bias\n",
      "blocks.10.norm1.weight\n",
      "blocks.10.norm1.bias\n",
      "blocks.10.attn.qkv.weight\n",
      "blocks.10.attn.qkv.bias\n",
      "blocks.10.attn.proj.weight\n",
      "blocks.10.attn.proj.bias\n",
      "blocks.10.norm2.weight\n",
      "blocks.10.norm2.bias\n",
      "blocks.10.mlp.fc1.weight\n",
      "blocks.10.mlp.fc1.bias\n",
      "blocks.10.mlp.fc2.weight\n",
      "blocks.10.mlp.fc2.bias\n",
      "blocks.11.norm1.weight\n",
      "blocks.11.norm1.bias\n",
      "blocks.11.attn.qkv.weight\n",
      "blocks.11.attn.qkv.bias\n",
      "blocks.11.attn.proj.weight\n",
      "blocks.11.attn.proj.bias\n",
      "blocks.11.norm2.weight\n",
      "blocks.11.norm2.bias\n",
      "blocks.11.mlp.fc1.weight\n",
      "blocks.11.mlp.fc1.bias\n",
      "blocks.11.mlp.fc2.weight\n",
      "blocks.11.mlp.fc2.bias\n",
      "norm.weight\n",
      "norm.bias\n",
      "head.weight\n",
      "head.bias\n"
     ]
    }
   ],
   "source": [
    "w_new = {}\n",
    "\n",
    "for i in w:\n",
    "    w_new[i[7:]] = w[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2e8bf0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T11:50:33.552184Z",
     "start_time": "2023-03-05T11:50:33.550068Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_new.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41efe5e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T16:31:51.593962Z",
     "start_time": "2023-03-05T16:31:51.119151Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47ceeee1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T17:18:10.693710Z",
     "start_time": "2023-03-05T17:18:10.682177Z"
    },
    "code_folding": [
     0,
     53
    ]
   },
   "outputs": [],
   "source": [
    "class MixStyle(nn.Module):\n",
    "    \"\"\"MixStyle.\n",
    "    Reference:\n",
    "      Zhou et al. Domain Generalization with MixStyle. ICLR 2021.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5, alpha=0.1, eps=1e-6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          p (float): probability of using MixStyle.\n",
    "          alpha (float): parameter of the Beta distribution.\n",
    "          eps (float): scaling parameter to avoid numerical issues.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.beta = torch.distributions.Beta(alpha, alpha)\n",
    "        self.eps = eps\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self._activated = True\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MixStyle(p={self.p}, alpha={self.alpha}, eps={self.eps})'\n",
    "\n",
    "    def set_activation_status(self, status=True):\n",
    "        self._activated = status\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training or not self._activated:\n",
    "            return x\n",
    "\n",
    "        if random.random() > self.p:\n",
    "            return x\n",
    "\n",
    "        B = x.size(0)\n",
    "\n",
    "        mu = x.mean(dim=[2, 3], keepdim=True)\n",
    "        var = x.var(dim=[2, 3], keepdim=True)\n",
    "        sig = (var + self.eps).sqrt()\n",
    "        mu, sig = mu.detach(), sig.detach()\n",
    "        x_normed = (x-mu) / sig\n",
    "\n",
    "        lmda = self.beta.sample((B, 1, 1, 1))\n",
    "        lmda = lmda.to(x.device)\n",
    "\n",
    "        perm = torch.randperm(B)\n",
    "        mu2, sig2 = mu[perm], sig[perm]\n",
    "        mu_mix = mu*lmda + mu2 * (1-lmda)\n",
    "        sig_mix = sig*lmda + sig2 * (1-lmda)\n",
    "\n",
    "        return x_normed*sig_mix + mu_mix\n",
    "\n",
    "\n",
    "class MixStyle2(nn.Module):\n",
    "    \"\"\"MixStyle (w/ domain prior).\n",
    "    The input should contain two equal-sized mini-batches from two distinct domains.\n",
    "    Reference:\n",
    "      Zhou et al. Domain Generalization with MixStyle. ICLR 2021.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=0.5, alpha=0.1, eps=1e-6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          p (float): probability of using MixStyle.\n",
    "          alpha (float): parameter of the Beta distribution.\n",
    "          eps (float): scaling parameter to avoid numerical issues.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.beta = torch.distributions.Beta(alpha, alpha)\n",
    "        self.eps = eps\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self._activated = True\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MixStyle(p={self.p}, alpha={self.alpha}, eps={self.eps})'\n",
    "\n",
    "    def set_activation_status(self, status=True):\n",
    "        self._activated = status\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        For the input x, the first half comes from one domain,\n",
    "        while the second half comes from the other domain.\n",
    "        \"\"\"\n",
    "        if not self.training or not self._activated:\n",
    "            return x\n",
    "\n",
    "        if random.random() > self.p:\n",
    "            return x\n",
    "\n",
    "        B = x.size(0)\n",
    "\n",
    "        mu = x.mean(dim=[2], keepdim=True)\n",
    "        var = x.var(dim=[2], keepdim=True)\n",
    "        sig = (var + self.eps).sqrt()\n",
    "        mu, sig = mu.detach(), sig.detach()\n",
    "        x_normed = (x-mu) / sig\n",
    "\n",
    "        lmda = self.beta.sample((B, 1, 1))\n",
    "        lmda = lmda.to(x.device)\n",
    "\n",
    "        perm = torch.arange(B - 1, -1, -1) # inverse index\n",
    "        perm_b, perm_a = perm.chunk(2)\n",
    "        perm_b = perm_b[torch.randperm(B // 2)]\n",
    "        perm_a = perm_a[torch.randperm(B // 2)]\n",
    "        perm = torch.cat([perm_b, perm_a], 0)\n",
    "\n",
    "        mu2, sig2 = mu[perm], sig[perm]\n",
    "        mu_mix = mu*lmda + mu2 * (1-lmda)\n",
    "        sig_mix = sig*lmda + sig2 * (1-lmda)\n",
    "\n",
    "        return x_normed*sig_mix + mu_mix\n",
    "    \n",
    "    \n",
    "class Intra_ADR(nn.Module):\n",
    "    def __init__(self, inp, outp, Norm=None, group=1, stride=1, **kwargs):\n",
    "        super(Intra_ADR, self).__init__()\n",
    "        self.E_space = nn.Sequential(\n",
    "            nn.ConvTranspose1d(inp, outp, kernel_size=2, stride=stride, padding=0, output_padding=0, groups=1,\n",
    "                               bias=True, dilation=1, padding_mode='zeros'),\n",
    "            nn.InstanceNorm1d(outp),\n",
    "            nn.ReLU(inplace=True),\n",
    "            )\n",
    "        self.mixstyle = MixStyle(p=.5, alpha=.3)\n",
    "        \n",
    "    def cc_kth_p(self, input, kth=0):\n",
    "        kth = 10\n",
    "        input = torch.topk(input, kth, dim=1)[0]  # n,k,h,w\n",
    "\n",
    "        input = input.mean(1, keepdim=True)\n",
    "        return input\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        print(x.shape)\n",
    "        branch = self.E_space(x)\n",
    "        branch2 = branch\n",
    "        print(branch.shape)\n",
    "\n",
    "        x_adr = branch\n",
    "        branch_ = branch #.reshape(branch.size(0), branch.size(1), branch.size(2) * branch.size(3))\n",
    "        branch = F.softmax(branch_, 2)\n",
    "        branch_out = self.cc_kth_p(branch)\n",
    "        return branch_out, branch2, x_adr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4509ef1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T17:17:52.139757Z",
     "start_time": "2023-03-05T17:17:52.137611Z"
    }
   },
   "outputs": [],
   "source": [
    "m = MixStyle2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8564c920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T17:17:52.644032Z",
     "start_time": "2023-03-05T17:17:52.640342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 197, 768])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(torch.rand((4,197,768))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd267166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T17:17:52.872381Z",
     "start_time": "2023-03-05T17:17:52.869446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1da5f62e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T17:18:21.243863Z",
     "start_time": "2023-03-05T17:18:21.239176Z"
    }
   },
   "outputs": [],
   "source": [
    "a = Intra_ADR(768,768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9fb38a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T17:18:23.358418Z",
     "start_time": "2023-03-05T17:18:23.309536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 768, 197])\n",
      "torch.Size([32, 768, 197])\n",
      "torch.Size([32, 768, 198])\n"
     ]
    }
   ],
   "source": [
    "o = a(torch.rand((32, 768, 197)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b98b7ad6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T17:18:23.831853Z",
     "start_time": "2023-03-05T17:18:23.829482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 198]), torch.Size([32, 768, 198]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0].shape, o[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d9a1126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T17:18:25.232051Z",
     "start_time": "2023-03-05T17:18:25.230228Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.vision_transformer import vit_base_patch16_224\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c1f947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T16:31:58.027548Z",
     "start_time": "2023-03-05T16:31:56.007392Z"
    }
   },
   "outputs": [],
   "source": [
    "m = vit_base_patch16_224(pretrained=True, num_classes=10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137efbe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T16:31:59.807858Z",
     "start_time": "2023-03-05T16:31:58.514523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 196, 768])\n",
      "torch.Size([4, 197, 768])\n",
      "torch.Size([4, 197, 768])\n",
      "torch.Size([4, 197, 768])\n",
      "torch.Size([4, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    o = m(torch.rand((4,3,224,224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41df38b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T16:32:01.516389Z",
     "start_time": "2023-03-05T16:32:01.512047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68adfb30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:43:52.596221Z",
     "start_time": "2023-03-07T16:43:50.551947Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 17:43:50.585988: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 17:43:50.744436: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-07 17:43:50.806039: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-07 17:43:51.447258: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64:\n",
      "2023-03-07 17:43:51.447297: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64:\n",
      "2023-03-07 17:43:51.447301: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa676fea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:43:52.607251Z",
     "start_time": "2023-03-07T16:43:52.602820Z"
    }
   },
   "outputs": [],
   "source": [
    "def se_module(x, filters, ratio=2):\n",
    "    \n",
    "    avg_pool = tf.keras.layers.GlobalAveragePooling2D()(x)    \n",
    "    \n",
    "\n",
    "    avg_pool = tf.keras.layers.Dense(filters//ratio,\n",
    "                             activation='relu')(avg_pool)\n",
    "\n",
    "    excitation = tf.keras.layers.Dense(filters, activation='sigmoid')(avg_pool)#\n",
    "    excitation = tf.keras.layers.Reshape((1,filters))(excitation)\n",
    "    \n",
    "    return tf.keras.layers.Multiply()([x, excitation])\n",
    "\n",
    "def red_module(x, filters, kernel_size):\n",
    "    x_res = x\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size, strides=(2,1), padding='same', activation='relu')(x)\n",
    "    x_res = tf.keras.layers.Conv2D(filters, 1, strides=(2,1), padding='same', activation='relu')(x_res)\n",
    "    \n",
    "    return tf.keras.layers.Add()([x_res, x])\n",
    "\n",
    "def resa_red_module(x, filters,  kernel_size):\n",
    "    x_res = x\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size, strides=1, padding='same', activation='relu')(x)\n",
    "    x = se_module(x, filters, ratio=4)\n",
    "    x = tf.keras.layers.Add()([x, x_res])\n",
    "    return red_module(x, filters, kernel_size)\n",
    "\n",
    "def resa_module(x, filters,  kernel_size):\n",
    "    x_res = x\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size, strides=1, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Add()([x, x_res])\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_model(input_shape, filters = 64, kernel_size = (3,1), n_modules =2):\n",
    "    input_tensor = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    # first compression                 \n",
    "    x = tf.keras.layers.Conv2D(filters, (3,1), strides=1, padding='same', activation='relu')(input_tensor)\n",
    "    \n",
    "    # main corpus\n",
    "    for i in range(n_modules):\n",
    "        x = resa_red_module(x, filters=filters, kernel_size=kernel_size)\n",
    "        \n",
    "    \n",
    "    # prediction\n",
    "    x_reg = tf.keras.layers.Flatten()(x)\n",
    "    x_reg = tf.keras.layers.Dropout(0.2)(x_reg)\n",
    "    output_tensor = tf.keras.layers.Dense(3, activation='linear')(x_reg)\n",
    "    \n",
    "    #x_class = tf.keras.layers.Flatten()(x)\n",
    "    #x_class = tf.keras.layers.Dropout(0.2)(x_class)\n",
    "    #output_class = tf.keras.layers.Dense(1, activation='sigmoid')(x_class)\n",
    "    \n",
    "    \n",
    "    return tf.keras.Model(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4666c7a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-07T16:45:11.309888Z",
     "start_time": "2023-03-07T16:45:11.197124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 10, 8, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 10, 8, 64)    256         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 10, 8, 64)    12352       ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 64)          0           ['conv2d_8[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 16)           1040        ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           1088        ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 64)        0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 10, 8, 64)    0           ['conv2d_8[0][0]',               \n",
      "                                                                  'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 10, 8, 64)    0           ['multiply_2[0][0]',             \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 5, 8, 64)     4160        ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 5, 8, 64)     12352       ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 5, 8, 64)     0           ['conv2d_10[0][0]',              \n",
      "                                                                  'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 5, 8, 64)     12352       ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 64)          0           ['conv2d_11[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 16)           1040        ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 64)           1088        ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 1, 64)        0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 5, 8, 64)     0           ['conv2d_11[0][0]',              \n",
      "                                                                  'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 5, 8, 64)     0           ['multiply_3[0][0]',             \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 3, 8, 64)     4160        ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 3, 8, 64)     12352       ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 3, 8, 64)     0           ['conv2d_13[0][0]',              \n",
      "                                                                  'conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 1536)         0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1536)         0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 3)            4611        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66,851\n",
      "Trainable params: 66,851\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = (10,8,1) # T,F,1\n",
    "\n",
    "model = build_model(INPUT_SIZE)\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.Adam(learning_rate = 0.00007))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98409969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kd",
   "language": "python",
   "name": "kd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
